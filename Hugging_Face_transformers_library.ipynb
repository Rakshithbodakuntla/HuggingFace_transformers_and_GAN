{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZtTPqwPdIJHx34OAR+VLW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakshithbodakuntla/HuggingFace_transformers_and_GAN/blob/main/Hugging_Face_transformers_library.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igg9tXSPUMnD",
        "outputId": "d8027b68-dc09-4f1b-cad3-0d342229f9bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Task 1: Basic QA Pipeline ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Charles Babbage\n",
            "Score: 0.9980111718177795\n",
            "Start Index: 0 | End Index: 15\n",
            "\n",
            "=== Task 2: Using Custom Model ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Charles Babbage\n",
            "Score: 0.9867498874664307\n",
            "Start Index: 0 | End Index: 15\n",
            "\n",
            "=== Task 3: Custom Example ===\n",
            "Q: Who was Ada Lovelace?\n",
            "A: an English mathematician | Score: 0.4544992446899414\n",
            "\n",
            "Q: Why is Ada Lovelace considered the first programmer?\n",
            "A: her visionary notes | Score: 0.5402531623840332\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# -------------------------------\n",
        "# Task 1: Basic Pipeline Setup\n",
        "# -------------------------------\n",
        "print(\"=== Task 1: Basic QA Pipeline ===\")\n",
        "qa_pipeline = pipeline(\"question-answering\")\n",
        "\n",
        "context_1 = \"Charles Babbage is considered the father of the computer. He designed the Analytical Engine in the 19th century.\"\n",
        "question_1 = \"Who is considered the father of the computer?\"\n",
        "\n",
        "result_1 = qa_pipeline(question=question_1, context=context_1)\n",
        "print(\"Answer:\", result_1['answer'])\n",
        "print(\"Score:\", result_1['score'])\n",
        "print(\"Start Index:\", result_1['start'], \"| End Index:\", result_1['end'])\n",
        "\n",
        "# -------------------------------\n",
        "# Task 2: Use a Custom Pretrained Model\n",
        "# -------------------------------\n",
        "print(\"\\n=== Task 2: Using Custom Model ===\")\n",
        "qa_pipeline_custom = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "\n",
        "result_2 = qa_pipeline_custom(question=question_1, context=context_1)\n",
        "print(\"Answer:\", result_2['answer'])\n",
        "print(\"Score:\", result_2['score'])\n",
        "print(\"Start Index:\", result_2['start'], \"| End Index:\", result_2['end'])\n",
        "\n",
        "# -------------------------------\n",
        "# Task 3: Test on Your Own Example\n",
        "# -------------------------------\n",
        "print(\"\\n=== Task 3: Custom Example ===\")\n",
        "context_3 = \"\"\"\n",
        "Ada Lovelace was an English mathematician known for her work on Charles Babbage's Analytical Engine.\n",
        "She is often regarded as the first computer programmer because of her visionary notes.\n",
        "\"\"\"\n",
        "\n",
        "question_3a = \"Who was Ada Lovelace?\"\n",
        "question_3b = \"Why is Ada Lovelace considered the first programmer?\"\n",
        "\n",
        "result_3a = qa_pipeline_custom(question=question_3a, context=context_3)\n",
        "result_3b = qa_pipeline_custom(question=question_3b, context=context_3)\n",
        "\n",
        "print(f\"Q: {question_3a}\")\n",
        "print(\"A:\", result_3a['answer'], \"| Score:\", result_3a['score'])\n",
        "\n",
        "print(f\"\\nQ: {question_3b}\")\n",
        "print(\"A:\", result_3b['answer'], \"| Score:\", result_3b['score'])\n"
      ]
    }
  ]
}